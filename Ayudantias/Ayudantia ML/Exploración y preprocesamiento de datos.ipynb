{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC1005 2018-1: Ayudant√≠a *Machine Learning*\n",
    "\n",
    "###### Por: Daniela Flores y Antonio Ossa.\n",
    "\n",
    "La idea de esta ayudant√≠a es guiar el pre-procesamiento de datos que debes realizar para tu tarea. Adem√°s, veremos un poco de validaci√≥n cruzada y entrenamiento de los modelos. El *dataset* que nos servir√° para ilustrar gran parte de lo que podr√≠as necesitar en tu tarea (¬°la idea es que investigues t√∫ tambi√©n!) es **Qualitative Bankruptcy**.\n",
    "\n",
    "## Qualitative Bankruptcy\n",
    "\n",
    "Las columnas del dataset y sus valores posibles son:\n",
    "\n",
    "```\n",
    "1. Industrial Risk: {P,A,N}\n",
    "2. Management Risk: {P,A,N}\n",
    "3. Financial Flexibility: {P,A,N}\n",
    "4. Credibility: {P,A,N}\n",
    "5. Competitiveness: {P,A,N}\n",
    "6. Operating Risk: {P,A,N}\n",
    "7. Class: {B,NB}\n",
    "8. Mysterious column: {P,A,N}\n",
    "```\n",
    "\n",
    "Para trabajar en la exploraci√≥n y pre-procesamiento de datos usaremos nuestra querida librer√≠a `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"qualitative-bankruptcy-data-ay.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "\n",
    "* Columna `id` no nos sirve.\n",
    "* Nombres de columnas pocos descriptivos.\n",
    "* Valores en filas no comparables.\n",
    "* Explorar correlaci√≥n entre columnas.\n",
    "\n",
    "A continuaci√≥n, nos haremos cargo de estas observaciones. En primer lugar, nos desharemos de la columna `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna 'id' no nos sirve\n",
    "data = data.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora renombramos las columnas para saber bien a qu√© hacen referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de columnas poco descriptivos\n",
    "data = data.rename(columns={\n",
    "    'IR': 'Industrial Risk',\n",
    "    'MR': 'Management Risk',\n",
    "    'FF': 'Financial Flexibility',\n",
    "    'CR': 'Credibility',\n",
    "    'CO': 'Competitiveness',\n",
    "    'OP': 'Operating Risk',\n",
    "    'MC': 'Mysterious Column'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos los valores *string* a datos num√©ricos que nos permitan trabajar sin problemas con los modelos en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores en filas no comparables\n",
    "meanings = {'P': 1, 'A': 0, 'N': -1}\n",
    "data = data.applymap(lambda v: meanings.get(v, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si dos o m√°s columnas tienen una alta correlaci√≥n, mantener ambas puede que no sea en extremo informativo. Para estudiar la correlacci√≥n entre columnas, `pandas` ofrece el m√©todo `corr` para sus `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorar correlaci√≥n entre columnas\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz√°s si lo vemos graficado en una colorida matriz podamos identificar alguna rareza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.matshow(data.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la correlaci√≥n entre las columnas `Mysterious Column` y `Competitiveness` es 1. Esto se debe a que ¬°sorpresa! ambas son la misma columna, solo tienen distinto nombre. Es importante notar que los datos fueron arreglados para que esto pasara. En la vida real, esto no es siempre tan evidente.\n",
    "\n",
    "Procedemos a eliminar la columna `Mysterious Column`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Mysterious Column', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver varias estad√≠sticas interesantes gracias al m√©todo `describe` de los `DataFrame` de `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificaci√≥n (simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Ahora viene un importante momento! Con el pre-procesamiento listo, procedemos a preparar los datos para entregarlos al modelo. Con esto en mente, utilizaremos `numpy` para separar los datos ($X$) del *target* ($y$, lo que queremos predecir). `ravel` nos permite obtener un arreglo unidimensional *aplanado*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ravel\n",
    "\n",
    "X = data[data.columns[:-1]]\n",
    "y = data[['Class']]\n",
    "y = ravel(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` es la librer√≠a que contiene varias herramientas que hacen m√°s sencillas las tareas relacionadas a aprendizaje de m√°quina. Para ejemplificar, utilizaremos los algoritmos de [*Support Vector Machine*](https://en.wikipedia.org/wiki/Support_vector_machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos qu√© tan bien *predice* nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üò± Nuestro modelo predice perfectamente, qu√© maravilla. Lamentablemente, esto no es √∫til en la realidad. Si revisamos la documentaci√≥n de [`sklearn`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.score), veremos que el m√©todo `score` deber√≠a recibir en $X$ observaciones de **prueba** y en $y$ las verdaderas etiquetas de esas observaciones de **prueba**. En nuestro ejemplo, **quisimos evaluar el modelo con los mismos datos con los que fue entrenado**, por esto era altamente probable que el *score* fuera perfecto, pues el modelo ya vio esas observaciones. Mostramos esto en ayudant√≠a para que en tu tarea (y en el resto de tu vida) siempre tengas la precauci√≥n de **no entrenar con los datos de prueba**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Cross validation*\n",
    "\n",
    "Quiz√°s te est√©s preguntando algo como: y si no puedo usar los mismos datos para entrenar y para testear, ¬øqu√© hago para probar mi modelo? Ah√≠ es cuando la validaci√≥n cruzada entra en juego como una gran aliada. Con este *approach*, el set de entrenamiento se divide en $k$ conjuntos m√°s peque√±os. Lo siguiente se realiza para cada uno de estos $k$ conjuntos:\n",
    "* Se entrena el modelo con $k-1$ sets.\n",
    "* El modelo resultante se prueba con el set restante.\n",
    "\n",
    "As√≠, procedemos a separar los datos en sets de entrenamiento y de *testing*. `sklearn` permite hacer esto con facilidad gracias a `train_test_split`. En nuestro ejemplo, dejaremos $60\\%$ de los datos para entrenar y el $40\\%$ restante para docimar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, usaremos validaci√≥n cruzada con 5 *folds*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.4, random_state=0)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=cv)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En este caso, vemos que nuestra *accuracy* es bastante alta, lo que se debe a las caracter√≠sticas del *dataset*. Normalmente no ser√° as√≠ :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusi√≥n\n",
    "\n",
    "La matriz de confusi√≥n es una herramienta que permite visualizar el desempe√±o de nuestro modelo. En las columnas se ubica el n√∫mero de predicciones de cada clase y en las filas est√°n las instancias en la clase real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
